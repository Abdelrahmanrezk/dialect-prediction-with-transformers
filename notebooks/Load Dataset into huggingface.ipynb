{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f666db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../assets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "659d813a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main libraries\n",
    "from data_shuffling_split import *\n",
    "from preprocess_text import *\n",
    "from datasets import load_dataset, list_datasets, Dataset, DatasetDict, ClassLabel\n",
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b853aa",
   "metadata": {},
   "source": [
    "# The Dataset\n",
    "\n",
    "The hugginface datasets library used either to use avaliable datasets on the hub or either to use your own dataset.\n",
    "\n",
    "### Load from avaliable data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e75c2dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4869\n",
      "['acronym_identification', 'ade_corpus_v2', 'adversarial_qa', 'aeslc', 'afrikaans_ner_corpus']\n"
     ]
    }
   ],
   "source": [
    "avaliable_dataset = list_datasets()\n",
    "print(len(avaliable_dataset))\n",
    "print(avaliable_dataset[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8cf52a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset emotion (/home/abdelrahman/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b242b66a2d864d4fa800aebef3b42cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 16000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emtions_data = load_dataset('emotion')\n",
    "emtions_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d766fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': Value(dtype='string', id=None), 'label': ClassLabel(num_classes=6, names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'], id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(emtions_data['train'].features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14c089dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['i didnt feel humiliated',\n",
       "  'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
       "  'im grabbing a minute to post i feel greedy wrong',\n",
       "  'i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n",
       "  'i am feeling grouchy'],\n",
       " 'label': [0, 0, 3, 2, 3]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emtions_data['train'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c57d71b",
   "metadata": {},
   "source": [
    "## Use our datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12e6ff8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "==================================================\n",
      "<class 'datasets.arrow_dataset.Dataset'>\n"
     ]
    }
   ],
   "source": [
    "strat_train_set = read_file(\"../dataset/dialect_data/train/strat_train_set.csv\")\n",
    "strat_dev_set   = read_file(\"../dataset/dialect_data/validation/strat_dev_set.csv\")\n",
    "strat_test_set  = read_file(\"../dataset/dialect_data/test/strat_test_set.csv\")\n",
    "\n",
    "strat_train_set.columns = ['id', 'label', 'text']\n",
    "strat_dev_set.columns   = ['id', 'label', 'text']\n",
    "strat_test_set.columns  = ['id', 'label', 'text']\n",
    "\n",
    "print(type(strat_train_set))\n",
    "\n",
    "# Convert to Dataset Apache arrow\n",
    "ds_strat_train_set = Dataset.from_pandas(strat_train_set)\n",
    "ds_strat_dev_set   = Dataset.from_pandas(strat_dev_set)\n",
    "ds_strat_test_set  = Dataset.from_pandas(strat_test_set)\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(type(ds_strat_train_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0028d2",
   "metadata": {},
   "source": [
    "# Convert dialect string to class label\n",
    "\n",
    "In this case we can easily convert to the correspond dialect when we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0ef8c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BH', 'JO', 'SA', 'QA', 'AE', 'DZ', 'EG', 'KW', 'TN', 'SY', 'LB', 'MA', 'OM', 'LY', 'SD', 'IQ', 'YE', 'PL']\n",
      "==================================================\n",
      "18\n",
      "==================================================\n",
      "ClassLabel(num_classes=18, names=['BH', 'JO', 'SA', 'QA', 'AE', 'DZ', 'EG', 'KW', 'TN', 'SY', 'LB', 'MA', 'OM', 'LY', 'SD', 'IQ', 'YE', 'PL'], id=None)\n"
     ]
    }
   ],
   "source": [
    "labels = list(set(ds_strat_train_set['label']))\n",
    "print(labels)\n",
    "print(\"=\"*50)\n",
    "print(len(labels))\n",
    "print(\"=\"*50)\n",
    "ClassLabels = ClassLabel(num_classes=len(labels), names=labels)\n",
    "print(ClassLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52654e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': Value(dtype='int64', id=None), 'label': Value(dtype='string', id=None), 'text': Value(dtype='string', id=None)}\n"
     ]
    }
   ],
   "source": [
    "# Look how the labels are string\n",
    "print(ds_strat_train_set.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "489e5a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8aee9ef194e4951a503bbd4f25284e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/441 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c9bb3437444694b9a576591fe1bffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/45 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb7cfe365d8458a9bef9af30b026751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fcd67f768784d0984aee68a0870df2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d6011be853247c8a9bd74625665caf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ba02dd607e471ebcabb9803cc456fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mapping Labels to IDs\n",
    "def map_dialect_str2int(data):\n",
    "    data['label'] = ClassLabels.str2int(data['label'])\n",
    "    return data\n",
    "\n",
    "ds_strat_train_set = ds_strat_train_set.map(map_dialect_str2int, batched=True)\n",
    "# Casting label column to ClassLabel Object\n",
    "ds_strat_train_set = ds_strat_train_set.cast_column('label', ClassLabels)\n",
    "\n",
    "\n",
    "\n",
    "ds_strat_dev_set = ds_strat_dev_set.map(map_dialect_str2int, batched=True)\n",
    "# Casting label column to ClassLabel Object\n",
    "ds_strat_dev_set = ds_strat_dev_set.cast_column('label', ClassLabels)\n",
    "\n",
    "\n",
    "ds_strat_test_set = ds_strat_test_set.map(map_dialect_str2int, batched=True)\n",
    "# Casting label column to ClassLabel Object\n",
    "ds_strat_test_set = ds_strat_test_set.cast_column('label', ClassLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fc18d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': Value(dtype='int64', id=None), 'label': ClassLabel(num_classes=18, names=['BH', 'JO', 'SA', 'QA', 'AE', 'DZ', 'EG', 'KW', 'TN', 'SY', 'LB', 'MA', 'OM', 'LY', 'SD', 'IQ', 'YE', 'PL'], id=None), 'text': Value(dtype='string', id=None)}\n"
     ]
    }
   ],
   "source": [
    "# Look how the labels are now ClassLabels\n",
    "print(ds_strat_train_set.features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9d8b8a",
   "metadata": {},
   "source": [
    "# Compare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f02f3aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Check our conversation ====================\n",
      "True\n",
      "True\n",
      "True\n",
      "['MA', 'LY', 'OM', 'PL', 'PL']\n",
      "['MA', 'LY', 'OM', 'PL', 'PL']\n",
      "==================================================\n",
      "['KW', 'JO', 'EG', 'AE', 'KW']\n",
      "['KW', 'JO', 'EG', 'AE', 'KW']\n",
      "==================================================\n",
      "['EG', 'DZ', 'SA', 'DZ', 'EG']\n",
      "['EG', 'DZ', 'SA', 'DZ', 'EG']\n"
     ]
    }
   ],
   "source": [
    "print(\"==================== Check our conversation ====================\")\n",
    "print(list(strat_train_set['label']) == ClassLabels.int2str(ds_strat_train_set['label']))\n",
    "print(list(strat_dev_set['label'])   == ClassLabels.int2str(ds_strat_dev_set['label']))\n",
    "print(list(strat_test_set['label']) == ClassLabels.int2str(ds_strat_test_set['label']))\n",
    "\n",
    "print(list(strat_train_set['label'])[:5])\n",
    "print(ClassLabels.int2str(ds_strat_train_set['label'][:5]))\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(list(strat_dev_set['label'])[:5])\n",
    "print(ClassLabels.int2str(ds_strat_dev_set['label'][:5]))\n",
    "\n",
    "\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(list(strat_test_set['label'])[:5])\n",
    "print(ClassLabels.int2str(ds_strat_test_set['label'][:5]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6aa8e780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'label', 'text'],\n",
       "        num_rows: 440052\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'label', 'text'],\n",
       "        num_rows: 9164\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'label', 'text'],\n",
       "        num_rows: 8981\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialect_datasets = DatasetDict()\n",
    "\n",
    "dialect_datasets['train']      = ds_strat_train_set\n",
    "dialect_datasets['validation'] = ds_strat_dev_set\n",
    "dialect_datasets['test']       = ds_strat_test_set\n",
    "\n",
    "dialect_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db215ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': Value(dtype='int64', id=None), 'label': ClassLabel(num_classes=18, names=['BH', 'JO', 'SA', 'QA', 'AE', 'DZ', 'EG', 'KW', 'TN', 'SY', 'LB', 'MA', 'OM', 'LY', 'SD', 'IQ', 'YE', 'PL'], id=None), 'text': Value(dtype='string', id=None)}\n",
      "==================================================\n",
      "{'id': Value(dtype='int64', id=None), 'label': ClassLabel(num_classes=18, names=['BH', 'JO', 'SA', 'QA', 'AE', 'DZ', 'EG', 'KW', 'TN', 'SY', 'LB', 'MA', 'OM', 'LY', 'SD', 'IQ', 'YE', 'PL'], id=None), 'text': Value(dtype='string', id=None)}\n",
      "==================================================\n",
      "{'id': Value(dtype='int64', id=None), 'label': ClassLabel(num_classes=18, names=['BH', 'JO', 'SA', 'QA', 'AE', 'DZ', 'EG', 'KW', 'TN', 'SY', 'LB', 'MA', 'OM', 'LY', 'SD', 'IQ', 'YE', 'PL'], id=None), 'text': Value(dtype='string', id=None)}\n"
     ]
    }
   ],
   "source": [
    "print(dialect_datasets['train'].features)\n",
    "print(\"=\"*50)\n",
    "print(dialect_datasets['validation'].features)\n",
    "print(\"=\"*50)\n",
    "print(dialect_datasets['test'].features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2977717",
   "metadata": {},
   "source": [
    "# Push the data into the hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8dec315",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0b3f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialect_datasets.push_to_hub('Abdelrahman-Rezk/Arabic_Dialect_Identification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2d76eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialect_datasets = load_dataset('Abdelrahman-Rezk/Arabic_Dialect_Identification')\n",
    "dialect_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb3d61d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
