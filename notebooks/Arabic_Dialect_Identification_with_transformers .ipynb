{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec3ea61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../assets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25a74e51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login successful\n",
      "Your token has been saved to /home/abdelrahman/.huggingface/token\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "703331d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main libraries\n",
    "from data_shuffling_split import *\n",
    "from preprocess_text import *\n",
    "from datasets import load_dataset, list_datasets, Dataset, DatasetDict, ClassLabel\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74e7343f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration Abdelrahman-Rezk--Arabic_Dialect_Identification-256d82f412398eec\n",
      "Reusing dataset parquet (/home/abdelrahman/.cache/huggingface/datasets/Abdelrahman-Rezk___parquet/Abdelrahman-Rezk--Arabic_Dialect_Identification-256d82f412398eec/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae313cdce2844f4a8cb902b7c8ae52a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'label', 'text'],\n",
       "        num_rows: 9164\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['id', 'label', 'text'],\n",
       "        num_rows: 440052\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'label', 'text'],\n",
       "        num_rows: 8981\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dialect_datasets = load_dataset('Abdelrahman-Rezk/Arabic_Dialect_Identification', use_auth_token=True)\n",
    "dialect_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "826ea9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'label', 'text']\n",
      "==================================================\n",
      "{'id': 1046024946705735552, 'label': 9, 'text': '@Ahmed_Hamza27 اتمنى صراحة و خصوصا #طال_عمره بينا وبينه قصة عشق قديمة😍😍'}\n",
      "==================================================\n",
      "{'id': Value(dtype='int64', id=None), 'label': ClassLabel(num_classes=18, names=['OM', 'SD', 'SA', 'KW', 'QA', 'LB', 'JO', 'SY', 'IQ', 'MA', 'EG', 'PL', 'YE', 'BH', 'DZ', 'AE', 'TN', 'LY'], id=None), 'text': Value(dtype='string', id=None)}\n",
      "==================================================\n",
      "{'id': [1046024946705735552, 1140189387508134016, 1051416181855440768], 'label': [9, 17, 0], 'text': ['@Ahmed_Hamza27 اتمنى صراحة و خصوصا #طال_عمره بينا وبينه قصة عشق قديمة😍😍', '@rJiM4CnIFTgml9g @zamnissi طبعا عرفته من اللي بشعار الليڤر', '@OmanisFollowers @ooredoo @TRA_OMAN @motc_om هيه هيه م يتغير شي.. كلهم ع بعضهم متولفين😪.. بيجيك مدير فرع قريب منك عشان يتساعد معك عشان بس يثبت جدارته لوظيفيه فكرسيه ويحاول يتعاون معك لكن فالنهايه بترجع ع نفس المشكله والدائرة تدور لا بيقدموا ولا بيأخروا😪😪.. وحدي غاسله ايدي منهم']}\n"
     ]
    }
   ],
   "source": [
    "train_data = dialect_datasets['train']\n",
    "print(train_data.column_names)\n",
    "print(\"=\"*50)\n",
    "print(train_data[0])\n",
    "print(\"=\"*50)\n",
    "print(train_data.features)\n",
    "print(\"=\"*50)\n",
    "print(train_data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26ccf3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1046024946705735552</td>\n",
       "      <td>9</td>\n",
       "      <td>@Ahmed_Hamza27 اتمنى صراحة و خصوصا #طال_عمره ب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1140189387508134016</td>\n",
       "      <td>17</td>\n",
       "      <td>@rJiM4CnIFTgml9g @zamnissi طبعا عرفته من اللي ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1051416181855440768</td>\n",
       "      <td>0</td>\n",
       "      <td>@OmanisFollowers @ooredoo @TRA_OMAN @motc_om ه...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>781770259422412800</td>\n",
       "      <td>11</td>\n",
       "      <td>كلب شو كنتوا بتتوقعوا منه !؟ \\n\\nمحمود عباس لا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>968140551366340608</td>\n",
       "      <td>11</td>\n",
       "      <td>#عزام 🔊\\nاحنا ابو الولد وام الولد</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  label  \\\n",
       "0  1046024946705735552      9   \n",
       "1  1140189387508134016     17   \n",
       "2  1051416181855440768      0   \n",
       "3   781770259422412800     11   \n",
       "4   968140551366340608     11   \n",
       "\n",
       "                                                text  \n",
       "0  @Ahmed_Hamza27 اتمنى صراحة و خصوصا #طال_عمره ب...  \n",
       "1  @rJiM4CnIFTgml9g @zamnissi طبعا عرفته من اللي ...  \n",
       "2  @OmanisFollowers @ooredoo @TRA_OMAN @motc_om ه...  \n",
       "3  كلب شو كنتوا بتتوقعوا منه !؟ \\n\\nمحمود عباس لا...  \n",
       "4                  #عزام 🔊\\nاحنا ابو الولد وام الولد  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.set_format(type=\"pandas\")\n",
    "df = train_data[:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0756232c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1046024946705735552</td>\n",
       "      <td>9</td>\n",
       "      <td>@Ahmed_Hamza27 اتمنى صراحة و خصوصا #طال_عمره ب...</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1140189387508134016</td>\n",
       "      <td>17</td>\n",
       "      <td>@rJiM4CnIFTgml9g @zamnissi طبعا عرفته من اللي ...</td>\n",
       "      <td>LY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1051416181855440768</td>\n",
       "      <td>0</td>\n",
       "      <td>@OmanisFollowers @ooredoo @TRA_OMAN @motc_om ه...</td>\n",
       "      <td>OM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>781770259422412800</td>\n",
       "      <td>11</td>\n",
       "      <td>كلب شو كنتوا بتتوقعوا منه !؟ \\n\\nمحمود عباس لا...</td>\n",
       "      <td>PL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>968140551366340608</td>\n",
       "      <td>11</td>\n",
       "      <td>#عزام 🔊\\nاحنا ابو الولد وام الولد</td>\n",
       "      <td>PL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  label  \\\n",
       "0  1046024946705735552      9   \n",
       "1  1140189387508134016     17   \n",
       "2  1051416181855440768      0   \n",
       "3   781770259422412800     11   \n",
       "4   968140551366340608     11   \n",
       "\n",
       "                                                text label_name  \n",
       "0  @Ahmed_Hamza27 اتمنى صراحة و خصوصا #طال_عمره ب...         MA  \n",
       "1  @rJiM4CnIFTgml9g @zamnissi طبعا عرفته من اللي ...         LY  \n",
       "2  @OmanisFollowers @ooredoo @TRA_OMAN @motc_om ه...         OM  \n",
       "3  كلب شو كنتوا بتتوقعوا منه !؟ \\n\\nمحمود عباس لا...         PL  \n",
       "4                  #عزام 🔊\\nاحنا ابو الولد وام الولد         PL  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def label_int2str(row):\n",
    "    return train_data.features['label'].int2str(row)\n",
    "df['label_name'] = df['label'].apply(label_int2str)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b0a362c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'label', 'text'],\n",
       "    num_rows: 440052\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7d3ad9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['label_name'].value_counts(ascending=True).plot.barh()\n",
    "plt.title(\"Frequency of Classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b075cb85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['tokens per tweet'] = df['text'].str.split().apply(len)\n",
    "df.boxplot(\"tokens per tweet\", by=\"label_name\", grid=False, showfliers=False, color=\"black\")\n",
    "plt.suptitle(\"\")\n",
    "plt.xlabel(\"\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f8bd220",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.reset_format()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1b76a0",
   "metadata": {},
   "source": [
    "## From Text to Tokens\n",
    "\n",
    "- تحديد انهى موديلز هنستخدمها\n",
    "- تحديد التكوينزر الخاص بكل موديل\n",
    "- التجريب على بعض الأمثلة من الداتا\n",
    "\n",
    "https://huggingface.co/CAMeL-Lab/bert-base-arabic-camelbert-da\n",
    "\n",
    "https://huggingface.co/CAMeL-Lab/bert-base-arabic-camelbert-msa\n",
    "\n",
    "https://huggingface.co/CAMeL-Lab/bert-base-arabic-camelbert-msa-did-madar-twitter5?text=%D8%B9%D8%A7%D9%85%D9%84+%D8%A7%D9%8A%D9%87+%D8%9F\n",
    "\n",
    "Edit tokenizer in our model to be limited to 124 word !?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221d2a8d",
   "metadata": {},
   "source": [
    "## Subword Tokenization\n",
    "The basic idea behind subword tokenization is to combine the best aspects of character and word tokenization. On the one hand, we want to split rare words into smaller units to allow the model to deal with complex words and misspellings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edb42b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"CAMeL-Lab/bert-base-arabic-camelbert-msa\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07294a75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'قلبي مقبوض ، بقالي كام يوم مش متظبط و اتمني ان دا يكون رواسب الزمن و متحصلش حاجه اوحش من اللي بيحصل ...'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_text = train_data['text'][8]\n",
    "some_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "936727c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2, 3018, 8755, 2175, 378, 10262, 1907, 3648, 2232, 2096, 2068, 1057, 2463, 415, 6228, 1939, 2720, 2461, 3275, 2024, 5579, 415, 8870, 2107, 1034, 3909, 2213, 24474, 1908, 2115, 27329, 2107, 18, 18, 18, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "encoded_text = tokenizer(some_text)\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b31bb58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'قلبي', 'مقب', '##وض', '،', 'بقا', '##لي', 'كام', 'يوم', 'مش', 'مت', '##ظ', '##بط', 'و', 'اتمني', 'ان', 'دا', 'يكون', 'روا', '##سب', 'الزمن', 'و', 'متح', '##صل', '##ش', 'حاجه', 'او', '##حش', 'من', 'اللي', 'بيح', '##صل', '.', '.', '.', '[SEP]']\n",
      "[CLS] قلبي مقبوض ، بقالي كام يوم مش متظبط و اتمني ان دا يكون رواسب الزمن و متحصلش حاجه اوحش من اللي بيحصل... [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(encoded_text['input_ids']))\n",
    "print(tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(encoded_text['input_ids'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5d2397e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n",
      "1000000000000000019884624838656\n",
      "['input_ids', 'token_type_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.vocab_size)\n",
    "print(tokenizer.model_max_length)\n",
    "print(tokenizer.model_input_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80b8909c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[2, 36, 7329, 16696, 67, 44, 3263, 1118, 1049, 8903, 27238, 23212, 415, 5770, 7, 4206, 67, 7276, 16163, 25919, 6967, 8918, 15785, 1370, 1370, 3, 0, 0, 0, 0, 0], [2, 36, 86, 1089, 1050, 1021, 1069, 1084, 1052, 18100, 1115, 1025, 21542, 1077, 1025, 36, 94, 3263, 1052, 25287, 1050, 8191, 29359, 1908, 2115, 2331, 2685, 2115, 1225, 1017, 3]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
     ]
    }
   ],
   "source": [
    "def tokenize(batch):\n",
    "    return tokenizer(batch['text'], padding=True, truncation=True)\n",
    "\n",
    "print(tokenize(train_data[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db4f9576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [2, 6078, 1908, 3696, 2139, 399, 1039, 4, 18, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['[CLS]', 'الهدف', 'من', 'الحياة', 'هو', 'س', '##ث', '[MASK]', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "batch = {}\n",
    "batch['text'] = \"الهدف من الحياة هو سث[MASK] . \"\n",
    "encoded_text = tokenize(batch)\n",
    "print(encoded_text)\n",
    "print(tokenizer.convert_ids_to_tokens(encoded_text['input_ids']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6576cb6d",
   "metadata": {},
   "source": [
    "### Model Special Token & ITs ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31394e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PAD] 0\n",
      "[UNK] 1\n",
      "[CLS] 2\n",
      "[SEP] 3\n",
      "[MASK] 4\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.pad_token, tokenizer.pad_token_id)\n",
    "print(tokenizer.unk_token, tokenizer.unk_token_id)\n",
    "print(tokenizer.cls_token, tokenizer.cls_token_id)\n",
    "print(tokenizer.sep_token, tokenizer.sep_token_id)\n",
    "print(tokenizer.mask_token, tokenizer.mask_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "333bd42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/abdelrahman/.cache/huggingface/datasets/Abdelrahman-Rezk___parquet/Abdelrahman-Rezk--Arabic_Dialect_Identification-256d82f412398eec/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-515e7b6ee544720d.arrow\n",
      "Loading cached processed dataset at /home/abdelrahman/.cache/huggingface/datasets/Abdelrahman-Rezk___parquet/Abdelrahman-Rezk--Arabic_Dialect_Identification-256d82f412398eec/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-ac6d7f06406e36c6.arrow\n",
      "Loading cached processed dataset at /home/abdelrahman/.cache/huggingface/datasets/Abdelrahman-Rezk___parquet/Abdelrahman-Rezk--Arabic_Dialect_Identification-256d82f412398eec/0.0.0/0b6d5799bb726b24ad7fc7be720c170d8e497f575d02d47537de9a5bac074901/cache-7545239bc7f1e59d.arrow\n"
     ]
    }
   ],
   "source": [
    "# batch_size=None to get the length inputs based on the large tweet\n",
    "dialect_datasets_encoded = dialect_datasets.map(tokenize, batched=True, batch_size=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94d5bcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'validation': ['id', 'label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'], 'train': ['id', 'label', 'text', 'input_ids', 'token_type_ids', 'attention_mask'], 'test': ['id', 'label', 'text', 'input_ids', 'token_type_ids', 'attention_mask']}\n"
     ]
    }
   ],
   "source": [
    "print(dialect_datasets_encoded.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ec3074d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0611cdb383a40fbb0bd447eba76e1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/419M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at CAMeL-Lab/bert-base-arabic-camelbert-msa were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# The AutoModel class converts the token encodings to embeddings\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AutoModel.from_pretrained(model_ckpt).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51765052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1af7ad88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tensor shape: torch.Size([1, 36])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(some_text, return_tensors=\"pt\")\n",
    "print(f\"Input tensor shape: {inputs['input_ids'].size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c03ac0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {k:v.to(device) for k,v in inputs.items()}\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab555ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 36, 768])\n"
     ]
    }
   ],
   "source": [
    "# [batch_size, n_tokens, hidden_dim]\n",
    "print(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0590ab5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_ids', 'token_type_ids', 'attention_mask']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_input_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f093381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hidden_states(batch):\n",
    "    # Place model inputs on the GPU\n",
    "    inputs = {k:v.to(device) for k,v in batch.items() if k in tokenizer.model_input_names}\n",
    "    with torch.no_grad():\n",
    "        last_hidden_state = model(**inputs).last_hidden_state\n",
    "    # Return vector for [CLS] token\n",
    "    return {\"hidden_state\": last_hidden_state[:,0].cpu().numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bf325e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialect_datasets_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d537705b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944ad4152e5e47809eae74aac65e811f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dialect_datasets_hidden \u001b[38;5;241m=\u001b[39m \u001b[43mdialect_datasets_encoded\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextract_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/datasets/dataset_dict.py:770\u001b[0m, in \u001b[0;36mDatasetDict.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_names, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, desc)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    768\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[0;32m--> 770\u001b[0m     {\n\u001b[1;32m    771\u001b[0m         k: dataset\u001b[38;5;241m.\u001b[39mmap(\n\u001b[1;32m    772\u001b[0m             function\u001b[38;5;241m=\u001b[39mfunction,\n\u001b[1;32m    773\u001b[0m             with_indices\u001b[38;5;241m=\u001b[39mwith_indices,\n\u001b[1;32m    774\u001b[0m             with_rank\u001b[38;5;241m=\u001b[39mwith_rank,\n\u001b[1;32m    775\u001b[0m             input_columns\u001b[38;5;241m=\u001b[39minput_columns,\n\u001b[1;32m    776\u001b[0m             batched\u001b[38;5;241m=\u001b[39mbatched,\n\u001b[1;32m    777\u001b[0m             batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m    778\u001b[0m             drop_last_batch\u001b[38;5;241m=\u001b[39mdrop_last_batch,\n\u001b[1;32m    779\u001b[0m             remove_columns\u001b[38;5;241m=\u001b[39mremove_columns,\n\u001b[1;32m    780\u001b[0m             keep_in_memory\u001b[38;5;241m=\u001b[39mkeep_in_memory,\n\u001b[1;32m    781\u001b[0m             load_from_cache_file\u001b[38;5;241m=\u001b[39mload_from_cache_file,\n\u001b[1;32m    782\u001b[0m             cache_file_name\u001b[38;5;241m=\u001b[39mcache_file_names[k],\n\u001b[1;32m    783\u001b[0m             writer_batch_size\u001b[38;5;241m=\u001b[39mwriter_batch_size,\n\u001b[1;32m    784\u001b[0m             features\u001b[38;5;241m=\u001b[39mfeatures,\n\u001b[1;32m    785\u001b[0m             disable_nullable\u001b[38;5;241m=\u001b[39mdisable_nullable,\n\u001b[1;32m    786\u001b[0m             fn_kwargs\u001b[38;5;241m=\u001b[39mfn_kwargs,\n\u001b[1;32m    787\u001b[0m             num_proc\u001b[38;5;241m=\u001b[39mnum_proc,\n\u001b[1;32m    788\u001b[0m             desc\u001b[38;5;241m=\u001b[39mdesc,\n\u001b[1;32m    789\u001b[0m         )\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    791\u001b[0m     }\n\u001b[1;32m    792\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/datasets/dataset_dict.py:771\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache_file_names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    768\u001b[0m     cache_file_names \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m}\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DatasetDict(\n\u001b[1;32m    770\u001b[0m     {\n\u001b[0;32m--> 771\u001b[0m         k: \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m            \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m            \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m            \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m            \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m            \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_proc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_proc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    790\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    791\u001b[0m     }\n\u001b[1;32m    792\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/datasets/arrow_dataset.py:2346\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2343\u001b[0m disable_tqdm \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m logging\u001b[38;5;241m.\u001b[39mis_progress_bar_enabled()\n\u001b[1;32m   2345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m num_proc \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 2346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_indices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_rank\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2350\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatched\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdrop_last_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdrop_last_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremove_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_memory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mload_from_cache_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_from_cache_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_file_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwriter_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_nullable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_nullable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_fingerprint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2363\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable_tqdm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2364\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2365\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2366\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2368\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_cache_file_name\u001b[39m(cache_file_name, rank):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/datasets/arrow_dataset.py:532\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    531\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 532\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    533\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[1;32m    535\u001b[0m     \u001b[38;5;66;03m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/datasets/arrow_dataset.py:499\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    492\u001b[0m self_format \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_type,\n\u001b[1;32m    494\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_kwargs,\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_columns,\n\u001b[1;32m    496\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_all_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns,\n\u001b[1;32m    497\u001b[0m }\n\u001b[1;32m    498\u001b[0m \u001b[38;5;66;03m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 499\u001b[0m out: Union[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatasetDict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m datasets: List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(out\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(out, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m [out]\n\u001b[1;32m    501\u001b[0m \u001b[38;5;66;03m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/datasets/fingerprint.py:458\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    452\u001b[0m             kwargs[fingerprint_name] \u001b[38;5;241m=\u001b[39m update_fingerprint(\n\u001b[1;32m    453\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fingerprint, transform, kwargs_for_fingerprint\n\u001b[1;32m    454\u001b[0m             )\n\u001b[1;32m    456\u001b[0m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 458\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/datasets/arrow_dataset.py:2734\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   2730\u001b[0m indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m   2731\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mslice\u001b[39m(i, i \u001b[38;5;241m+\u001b[39m batch_size)\u001b[38;5;241m.\u001b[39mindices(input_dataset\u001b[38;5;241m.\u001b[39mnum_rows)))\n\u001b[1;32m   2732\u001b[0m )  \u001b[38;5;66;03m# Something simpler?\u001b[39;00m\n\u001b[1;32m   2733\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2734\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[43mapply_function_on_filtered_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2735\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2736\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2737\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_same_num_examples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minput_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2738\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2739\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2740\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   2741\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   2742\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2743\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/datasets/arrow_dataset.py:2614\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   2612\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m with_rank:\n\u001b[1;32m   2613\u001b[0m     additional_args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (rank,)\n\u001b[0;32m-> 2614\u001b[0m processed_inputs \u001b[38;5;241m=\u001b[39m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madditional_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m update_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2616\u001b[0m     \u001b[38;5;66;03m# Check if the function returns updated examples\u001b[39;00m\n\u001b[1;32m   2617\u001b[0m     update_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(processed_inputs, (Mapping, pa\u001b[38;5;241m.\u001b[39mTable))\n",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36mextract_hidden_states\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_hidden_states\u001b[39m(batch):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Place model inputs on the GPU\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {k:v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mmodel_input_names}\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      5\u001b[0m         last_hidden_state \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\u001b[38;5;241m.\u001b[39mlast_hidden_state\n",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_hidden_states\u001b[39m(batch):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Place model inputs on the GPU\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {k:\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device) \u001b[38;5;28;01mfor\u001b[39;00m k,v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mmodel_input_names}\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      5\u001b[0m         last_hidden_state \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\u001b[38;5;241m.\u001b[39mlast_hidden_state\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "dialect_datasets_hidden = dialect_datasets_encoded.map(extract_hidden_states, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da10c685",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
